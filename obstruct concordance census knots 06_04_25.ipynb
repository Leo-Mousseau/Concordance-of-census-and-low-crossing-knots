{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c0223bc-3e21-4a61-b3e5-4dbb4a6450c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snappy\n",
    "import csv\n",
    "import ast\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "from itertools import combinations_with_replacement\n",
    "######### braid words\n",
    "braid_words_file=open('/Users/leomousseau/Desktop/slice genera part 2/census seminar github/braid_words.txt','r')\n",
    "braid_words_string=braid_words_file.read()\n",
    "braid_words_list=ast.literal_eval(braid_words_string)\n",
    "braid_dict=dict(braid_words_list)\n",
    "#### pd codes\n",
    "pd_codes=[]\n",
    "with open('/Users/leomousseau/Desktop/census knots concordance/pd_codes.csv','r') as inp:\n",
    "    reader=csv.reader(inp)\n",
    "    for row in reader:\n",
    "        pd_codes.append(row)\n",
    "for k in pd_codes:\n",
    "    k[1]=literal_eval(k[1])\n",
    "pd_dict=dict(pd_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11497ffc-ab6b-49e7-b085-8d80e05512ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror(braid_word):\n",
    "    return([-x for x in braid_word])\n",
    "def reverse_orientation(braid_word):\n",
    "    return(braid_word[::-1])\n",
    "def connected_sum(w1,w2):\n",
    "    n=max([abs(k) for k in w1])\n",
    "    w3=[k+n if k>0 else -(-k+n) for k in w2]\n",
    "    return(w1+w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ded34e-3e77-4742-8cfa-86d5eee8cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773b5082-a922-4f47-bd8b-5d9fd003233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done!\n",
      "‚úîÔ∏è  Possibly concordant: 50784\n",
      "‚ùå Definitely not concordant: 3162328\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import ast\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "### ---- Load Invariants ----\n",
    "\n",
    "def load_csv_as_dict(path, key_index=0, val_index=1, eval_value=True, cast=int):\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                key = row[key_index]\n",
    "                val = row[val_index]\n",
    "                if eval_value:\n",
    "                    val = ast.literal_eval(val)\n",
    "                if cast:\n",
    "                    val = cast(val)\n",
    "                data.append((key, val))\n",
    "            except:\n",
    "                continue\n",
    "    return dict(data)\n",
    "\n",
    "# Paths\n",
    "base_path = '/Users/leomousseau/Desktop/slice genera part 2/census seminar github'\n",
    "group_path = base_path + '/group_A/computed results'\n",
    "knot_floer_path = '/Users/leomousseau/Desktop/slice genera part 2/knot_floer.csv'\n",
    "braid_path = base_path + '/braid_words.txt'\n",
    "\n",
    "# Load braid words\n",
    "with open(braid_path, 'r') as f:\n",
    "    braid_words_list = ast.literal_eval(f.read())\n",
    "braid_dict = dict(braid_words_list)\n",
    "names = list(braid_dict.keys())\n",
    "\n",
    "# Load invariants\n",
    "s_dict = load_csv_as_dict(base_path + '/invariants/sinvariants.csv')\n",
    "sign_dict = load_csv_as_dict(group_path + '/signature.csv', eval_value=True, cast=int)\n",
    "\n",
    "# From knot floer\n",
    "knot_floer = []\n",
    "with open(knot_floer_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        knot_floer.append(row)\n",
    "\n",
    "tau_dict = {}\n",
    "eps_dict = {}\n",
    "for row in knot_floer:\n",
    "    name = row[0]\n",
    "    try:\n",
    "        tau_dict[name] = int(ast.literal_eval(row[7]))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        eps_dict[name] = int(ast.literal_eval(row[2]))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "### ---- Concordance Filtering ----\n",
    "\n",
    "variant_types = [\n",
    "    ('identity', False),\n",
    "    ('reverse', False),\n",
    "    ('mirror', True),\n",
    "    ('reverse_mirror', True)\n",
    "]\n",
    "\n",
    "def maybe_negate(x, flip):\n",
    "    return -x if (x is not None and flip) else x\n",
    "\n",
    "def get_variant_invariants(k2, flip, s_dict, sign_dict, tau_dict, eps_dict):\n",
    "    return {\n",
    "        's-invariant': maybe_negate(s_dict.get(k2), flip),\n",
    "        'signature': maybe_negate(sign_dict.get(k2), flip),\n",
    "        'tau': maybe_negate(tau_dict.get(k2), flip),\n",
    "        'epsilon': maybe_negate(eps_dict.get(k2), flip)\n",
    "    }\n",
    "\n",
    "def check_invariants(k1, k2_variant, s_dict, sign_dict, tau_dict, eps_dict):\n",
    "    invariants = {\n",
    "        's-invariant': (s_dict.get(k1), k2_variant['s-invariant']),\n",
    "        'signature': (sign_dict.get(k1), k2_variant['signature']),\n",
    "        'tau': (tau_dict.get(k1), k2_variant['tau']),\n",
    "        'epsilon': (eps_dict.get(k1), k2_variant['epsilon']),\n",
    "    }\n",
    "    for name, (a, b) in invariants.items():\n",
    "        if a is not None and b is not None and a != b:\n",
    "            return False, f\"{name}: {a} vs {b}\"\n",
    "    return True, None\n",
    "\n",
    "### ---- Main Filtering Loop ----\n",
    "\n",
    "possibly_concordant = []\n",
    "definitely_not_concordant = []\n",
    "\n",
    "for k1, k2 in combinations_with_replacement(names, 2):\n",
    "    for variant_name, flip in variant_types:\n",
    "        k2_variant = get_variant_invariants(k2, flip, s_dict, sign_dict, tau_dict, eps_dict)\n",
    "        ok, reason = check_invariants(k1, k2_variant, s_dict, sign_dict, tau_dict, eps_dict)\n",
    "        if ok:\n",
    "            possibly_concordant.append((k1, k2, variant_name))\n",
    "        else:\n",
    "            definitely_not_concordant.append((k1, k2, variant_name, reason))\n",
    "\n",
    "### ---- Save Results ----\n",
    "\n",
    "with open(\"possibly_concordant_variants.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Knot1\", \"Knot2\", \"Variant\"])\n",
    "    writer.writerows(possibly_concordant)\n",
    "\n",
    "with open(\"definitely_not_concordant_variants.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Knot1\", \"Knot2\", \"Variant\", \"Obstruction\"])\n",
    "    writer.writerows(definitely_not_concordant)\n",
    "\n",
    "print(\"‚úÖ Done!\")\n",
    "print(f\"‚úîÔ∏è  Possibly concordant: {len(possibly_concordant)}\")\n",
    "print(f\"‚ùå Definitely not concordant: {len(definitely_not_concordant)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b1c98-95b3-497b-b5de-a599cbbe2fd1",
   "metadata": {},
   "source": [
    "let us also remove all census knots which are known to be slice and therefore concordant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea7603d-1f12-4673-84c4-3f7bfdc574f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_census=['m032', 'm222', 'm372', 's704', 's879', 'v1971', 'v2272', 'v2362', 'v2508', 'v2543', 'v2861', 'v3195', 'v3423', 'v3536', 't07281', 't07452', 't07599', 't08306', 't08617', 't10887', 't10974', 't11248', 't11418', 't11532', 't11577', 't12200', 't12587', 't12607', 't12630', 't12748', 'o9_12414', 'o9_18772', 'o9_18931', 'o9_20458', 'o9_20894', 'o9_22066', 'o9_29992', 'o9_30430', 'o9_31828', 'o9_34949', 'o9_35240', 'o9_36180', 'o9_36357', 'o9_36459', 'o9_37618', 'o9_37770', 'o9_38600', 'o9_39433', 'o9_39806', 'o9_39930', 'o9_39967', 'o9_40361', 'o9_40519', 'o9_40873', 'o9_41312', 'o9_41909', 'o9_42515', 'o9_42735', 'o9_43407', 'o9_43446']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93336d8-3f3c-4bd2-9e44-0fee889a35d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slice_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be20d9b-8ab9-4c67-804f-00648c21bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_concordant = [\n",
    "    (name1, name2, kind) for (name1, name2, kind) in possibly_concordant\n",
    "    if name1 not in slice_census and name2 not in slice_census\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4daa3469-e5e4-46aa-a91e-38ad1b43ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30744"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_concordant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8c897-facc-41ba-ae12-d2e0d3ceab41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e065f9-a4cf-4f5d-ae9a-2884343de7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e2a03-53d4-4903-b8f0-f7bed8a4b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Looking at (2, 3) ...\n",
      "t00027 t12395 mirror obstructed (2, 3) 1 50784\n",
      "   Looking at (2, 3) ...\n",
      "t00027 t12395 reverse_mirror obstructed (2, 3) 2 50784\n",
      "   Looking at (2, 3) ...\n",
      "   Looking at (3, 2) ...\n",
      "   Looking at (3, 5) ...\n",
      "   Looking at (3, 7) ...\n",
      "t00027 t12757 identity obstructed (3, 7) 3 50784\n",
      "   Looking at (2, 3) ...\n",
      "   Looking at (3, 2) ...\n",
      "   Looking at (3, 5) ...\n",
      "   Looking at (3, 7) ...\n",
      "t00027 t12757 reverse obstructed (3, 7) 4 50784\n",
      "   Looking at (2, 3) ...\n",
      "t00027 o9_00022 mirror obstructed (2, 3) 5 50784\n",
      "   Looking at (2, 3) ...\n",
      "t00027 o9_00022 reverse_mirror obstructed (2, 3) 6 50784\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "further_obstructed = []\n",
    "possibly_concordant2 = []\n",
    "c = 0\n",
    "\n",
    "for name1, name2, kind in filtered_concordant[10000:]:\n",
    "    c += 1\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Log progress to terminal and file\n",
    "    print(f\"\\n[{c}/{len(filtered_concordant)}] Processing: {name1}, {name2}, {kind}\")\n",
    "    with open(\"currently_processing.txt\", \"w\") as f:\n",
    "        f.write(f\"{c}/{len(filtered_concordant)}: {name1}, {name2}, {kind}\\n\")\n",
    "\n",
    "    try:\n",
    "        w1 = braid_dict[name1]\n",
    "\n",
    "        if kind == 'identity':\n",
    "            w2 = braid_dict[name2]\n",
    "        elif kind == 'reverse':\n",
    "            w2 = reverse_orientation(braid_dict[name2])\n",
    "        elif kind == 'mirror':\n",
    "            w2 = mirror(braid_dict[name2])\n",
    "        elif kind == 'reverse_mirror':\n",
    "            w2 = reverse_orientation(mirror(braid_dict[name2]))\n",
    "        else:\n",
    "            print('‚ùå Unknown kind:', kind)\n",
    "            continue\n",
    "\n",
    "        w = connected_sum(w1, reverse_orientation(mirror(w2)))\n",
    "        M = snappy.Link(braid_closure=w).exterior()\n",
    "        spec = [(20, [0, 20])]\n",
    "\n",
    "        p = 1\n",
    "        max_attempts = 5\n",
    "        attempt = 0\n",
    "        success = False\n",
    "\n",
    "        while p != 0 and attempt < max_attempts:\n",
    "            try:\n",
    "                print(f\"Attempt {attempt+1}: Running HKL obstruction...\")\n",
    "                obstr = M.slice_obstruction_HKL(spec, verbose=True)\n",
    "                p = 0\n",
    "                success = True\n",
    "\n",
    "                if isinstance(obstr, tuple):  # obstruction found\n",
    "                    row = [name1, name2, kind, f\"HKL obstruction {obstr}\"]\n",
    "                    further_obstructed.append(row)\n",
    "                    print(\"‚úÖ Obstructed:\", obstr)\n",
    "                else:\n",
    "                    row = [name1, name2, kind]\n",
    "                    possibly_concordant2.append(row)\n",
    "                    print(\"‚ûñ Not obstructed\")\n",
    "\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                M.randomize()\n",
    "                print(f\"‚ö†Ô∏è Attempt {attempt} failed:\", e)\n",
    "\n",
    "        if not success:\n",
    "            print(f\"‚ùå Totally stuck on: {name1}, {name2}, {kind}\")\n",
    "            with open(\"stuck_pairs.csv\", \"a\", newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([name1, name2, kind, \"stuck after retries\"])\n",
    "\n",
    "        # Save results after each pair\n",
    "        with open(\"further_obstructed_04_04_2025_2.csv\", \"w\", newline='') as f_out:\n",
    "            writer = csv.writer(f_out)\n",
    "            writer.writerow([\"name1\", \"name2\", \"kind\", \"obstruction\"])\n",
    "            writer.writerows(further_obstructed)\n",
    "\n",
    "        with open(\"possibly_concordant_04_04_2025_2.csv\", \"w\", newline='') as f_out:\n",
    "            writer = csv.writer(f_out)\n",
    "            writer.writerow([\"name1\", \"name2\", \"kind\"])\n",
    "            writer.writerows(possibly_concordant2)\n",
    "\n",
    "        # Optional: print how long that one took\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"‚è±Ô∏è Time for this pair: {elapsed:.1f} sec\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üí• CRASH on {name1}, {name2}, {kind}: {e}\")\n",
    "        with open(\"stuck_pairs.csv\", \"a\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([name1, name2, kind, str(e)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d96b16ae-a4df-495d-b5df-f5d2bb09212f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name1='v0321'\n",
    "name2='o9_33568'\n",
    "w1=braid_dict[name1]\n",
    "w2=braid_dict[name2]\n",
    "K1=snappy.Link(braid_closure=w1)\n",
    "K2=snappy.Link(braid_closure=w2)\n",
    "K1.simplify('global')\n",
    "K2.simplify('global')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb86d8b8-7122-405c-921b-fd61a52cfe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, -1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K1.knot_floer_homology()['tau'],K2.knot_floer_homology()['tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce19ea9-f7cb-4a42-9a70-e1435bd2f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "10034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a41b2-b7a7-40ea-9996-d56df326f2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856bb0c-7d92-47b0-ac19-a2d3a9aefe97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c6d487a-ecff-4f66-9524-82f5062ff01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14144, 4104)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(further_obstructed),len(possibly_concordant2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a751d-e986-4b8a-87d7-8302a1773ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5bbe8-3055-47bb-aff9-7c10449cf635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca2bff-a5d0-4a0f-a575-ede388bf4883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea995f-528f-4278-96a9-8486b2a1d9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b229b-6a37-4995-b9b5-489fa7ad50e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51b21c7c-21f5-4553-8543-8da0a108a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## signature function\n",
    "signature_function=[]\n",
    "with open('/Users/leomousseau/Desktop/slice genera part 2/census seminar github/group_A/computed results/signature_function_result.csv','r') as inp:\n",
    "    reader=csv.reader(inp)\n",
    "    for row in reader:\n",
    "        signature_function.append(row)\n",
    "del signature_function[0]\n",
    "for i in range(len(signature_function)):\n",
    "    l=[]\n",
    "    for k in signature_function[i][1:]:\n",
    "        try:\n",
    "            k=literal_eval(k)\n",
    "        except:\n",
    "            None\n",
    "        l.append(k)\n",
    "    signature_function[i]=[signature_function[i][0],l]\n",
    "signature_function_dict=dict(signature_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099e88a-e2ca-455f-b878-d424110cee29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21151ce-58ae-4134-87c6-f632ef524a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a133f-0483-4496-8868-44ac2e95eae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b966c-db9b-41fb-a61f-7aee043108df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2916bb17-46b9-4a71-a39d-6ad9bcd1afcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t11497', 'o9_39339', 'mirror')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name1=possibly_concordant[30000][0]\n",
    "name2=possibly_concordant[30000][1]\n",
    "kind=possibly_concordant[30000][2]\n",
    "name1,name2,kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecab19cc-139e-4b71-bc56-6f75ed4e570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=braid_dict[name1]\n",
    "w2=braid_dict[name2]\n",
    "K1=snappy.Link(braid_closure=w1)\n",
    "K2=snappy.Link(braid_closure=w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abf2a865-2424-45e5-8538-9f975f28f5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, -2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K1.signature(),K2.signature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8e4dc58-1945-4438-a8c3-a85a8799212e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'t11497'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname1\u001b[49m\u001b[43m]\u001b[49m,s_dict[name2]\n",
      "\u001b[0;31mKeyError\u001b[0m: 't11497'"
     ]
    }
   ],
   "source": [
    "s_dict[name1],s_dict[name2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "294439a9-73b5-4dc1-a648-43b6edd7c94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_dict[name1],tau_dict[name2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07e5664f-1702-4dc5-81b5-29378b186fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_dict[name1],eps_dict[name2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66fcddf0-5564-442d-a7f0-2145814af902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.5697, 0, -1, -2, 0, 1, 0]], [[0.121, 0, 1, 2, 0, 1, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature_function_dict[name1],signature_function_dict[name2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2579da1b-0e11-4e24-8bbf-afa1fb9bc31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=connected_sum(w1,reverse_orientation(mirror(mirror(w2))))\n",
    "K=snappy.Link(braid_closure=w)\n",
    "K.simplify('global')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "385d6aed-7ea9-45a2-a273-36c45b38d1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.signature(),K.knot_floer_homology()['tau'],K.knot_floer_homology()['epsilon'],K.knot_floer_homology()['nu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2fe5fbc3-8387-4350-aca1-4089e180c6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Looking at (2, 3) ...\n",
      "   Looking at (3, 2) ...\n"
     ]
    }
   ],
   "source": [
    "M=K.exterior()\n",
    "spec=[(100,[0,100])]\n",
    "obstr=M.slice_obstruction_HKL(spec,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc51b047-5d43-4ef4-a157-035ef7c1f3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "48d6b9c0-aa2a-4931-adf6-1ca46cdca9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=snappy.Link('6_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7eeba4c2-6f9a-40eb-9821-aa76e288dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=snappy.Link('4_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cad3a9a0-176c-479b-8caf-b43dbbcbdf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=snappy.Link('3_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "df53f3be-7c27-43de-89a1-88073650141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=K.exterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a0223b2a-5106-44b8-a9a6-c24f13e11ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Looking at (2, 3) ...\n",
      "   Looking at (3, 2) ...\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "M=K.exterior()\n",
    "spec=[(100,[0,100])]\n",
    "obstr=M.slice_obstruction_HKL(spec,verbose=True)\n",
    "print(obstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a8bdcdf6-3554-435b-854b-c814f0b4eea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t^4 - t^3 + t^2 - t + 1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.alexander_polynomial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ff8b14ee-0d90-48c4-8c82-12e182ef0018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Looking at (2, 5) ...\n",
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "K=snappy.Link('5_1')\n",
    "M=K.exterior()\n",
    "spec=[(100,[0,100])]\n",
    "spec=[(10, [0, 20]), (20, [0, 10])]\n",
    "obstr=M.slice_obstruction_HKL(spec,verbose=True)\n",
    "print(obstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9f246307-7626-4207-a102-8dc9bb3630dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(obstr)==tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3403f64-1ba5-4218-be23-c4c078f2e366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
